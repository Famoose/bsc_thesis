{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:50:45.981726Z",
     "start_time": "2024-04-24T10:50:45.970126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Param\n",
    "TOTAL_TIMESTEP_NUMB = 200_000\n",
    "LEARNING_RATE = 0.0001\n",
    "GAE = 1.0\n",
    "ENT_COEF = 0.01\n",
    "N_STEPS = 512\n",
    "GAMMA = 0.9\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10\n",
    "\n",
    "# Test Param\n",
    "EVAL_FREQ = 10000\n",
    "TEST_EPISODE_NUMBERS = 10"
   ],
   "id": "190e8d813e519441",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:50:45.997228Z",
     "start_time": "2024-04-24T10:50:45.983226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "save_dir = Path('./parallel')"
   ],
   "id": "356c5b9f625e9698",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:50:48.106379Z",
     "start_time": "2024-04-24T10:50:45.998228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model_cnn import MarioNet\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MarioNet,\n",
    "    features_extractor_kwargs=dict(features_dim=512),\n",
    ")"
   ],
   "id": "5e5076bbc86f9dfc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T10:51:02.790Z",
     "start_time": "2024-04-24T10:50:48.107379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import make_parallel_env, STAGE_PIXEL\n",
    "\n",
    "env_1 = make_parallel_env(STAGE_PIXEL, 1)\n",
    "env_2 = make_parallel_env(STAGE_PIXEL, 2)\n",
    "env_4 = make_parallel_env(STAGE_PIXEL, 4)\n",
    "env_8 = make_parallel_env(STAGE_PIXEL, 8)\n",
    "env_16 = make_parallel_env(STAGE_PIXEL, 16)\n",
    "\n",
    "# dict with the different environments and names\n",
    "env = {\n",
    "    'ENV_NUM_1': env_1,\n",
    "    'ENV_NUM_2': env_2,\n",
    "    'ENV_NUM_4': env_4,\n",
    "    'ENV_NUM_8': env_8,\n",
    "    'ENV_NUM_16': env_16\n",
    "}"
   ],
   "id": "ae5282df420a1cc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T13:56:59.250984Z",
     "start_time": "2024-04-24T10:51:02.791501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import TrainAndLoggingCallback\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "eval = make_parallel_env(STAGE_PIXEL, 1)\n",
    "\n",
    "for key in env.keys():\n",
    "    print(f\"Training {key}\")\n",
    "    model = PPO('CnnPolicy', env[key], verbose=0, policy_kwargs=policy_kwargs, tensorboard_log=save_dir,\n",
    "                learning_rate=LEARNING_RATE, n_steps=N_STEPS, batch_size=BATCH_SIZE, n_epochs=N_EPOCHS, gamma=GAMMA, gae_lambda=GAE, ent_coef=ENT_COEF)\n",
    "    callback = TrainAndLoggingCallback(test_env=eval, check_freq=EVAL_FREQ, episode_num=TEST_EPISODE_NUMBERS)\n",
    "    model.learn(total_timesteps=TOTAL_TIMESTEP_NUMB, tb_log_name=key, callback=callback)"
   ],
   "id": "b979069e0aa609ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ENV_NUM_1\n",
      "time steps: 10000\n",
      "average reward: 661.7 average time: 129.5 best_reward: 1122.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\PycharmProjects\\bsc_thesis\\utils.py:159: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  Video(th.ByteTensor([screens]), fps=40),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 20000\n",
      "average reward: 717.7 average time: 150.8 best_reward: 1128.0\n",
      "time steps: 30000\n",
      "average reward: 678.1 average time: 144.4 best_reward: 1130.0\n",
      "time steps: 40000\n",
      "average reward: 530.5 average time: 98.3 best_reward: 1046.0\n",
      "time steps: 50000\n",
      "average reward: 586.4 average time: 177.4 best_reward: 1024.0\n",
      "time steps: 60000\n",
      "average reward: 699.7 average time: 153.8 best_reward: 1304.0\n",
      "time steps: 70000\n",
      "average reward: 550.2 average time: 117.0 best_reward: 809.0\n",
      "time steps: 80000\n",
      "average reward: 646.0 average time: 135.5 best_reward: 1300.0\n",
      "time steps: 90000\n",
      "average reward: 643.7 average time: 128.7 best_reward: 1035.0\n",
      "time steps: 100000\n",
      "average reward: 657.2 average time: 141.7 best_reward: 1028.0\n",
      "time steps: 110000\n",
      "average reward: 730.8 average time: 147.1 best_reward: 1403.0\n",
      "time steps: 120000\n",
      "average reward: 891.7 average time: 172.4 best_reward: 2595.0\n",
      "time steps: 130000\n",
      "average reward: 737.6 average time: 145.4 best_reward: 1312.0\n",
      "time steps: 140000\n",
      "average reward: 926.1 average time: 174.5 best_reward: 3004.0\n",
      "time steps: 150000\n",
      "average reward: 614.7 average time: 123.4 best_reward: 1115.0\n",
      "time steps: 160000\n",
      "average reward: 638.8 average time: 121.4 best_reward: 1038.0\n",
      "time steps: 170000\n",
      "average reward: 770.4 average time: 162.6 best_reward: 1309.0\n",
      "time steps: 180000\n",
      "average reward: 495.3 average time: 93.1 best_reward: 1302.0\n",
      "time steps: 190000\n",
      "average reward: 707.0 average time: 125.3 best_reward: 1407.0\n",
      "time steps: 200000\n",
      "average reward: 824.9 average time: 189.2 best_reward: 1863.0\n",
      "Training ENV_NUM_2\n",
      "time steps: 20000\n",
      "average reward: 650.7 average time: 145.5 best_reward: 1047.0\n",
      "time steps: 40000\n",
      "average reward: 593.5 average time: 120.6 best_reward: 1299.0\n",
      "time steps: 60000\n",
      "average reward: 768.3 average time: 160.2 best_reward: 1297.0\n",
      "time steps: 80000\n",
      "average reward: 708.0 average time: 200.2 best_reward: 1385.0\n",
      "time steps: 100000\n",
      "average reward: 736.7 average time: 151.2 best_reward: 1307.0\n",
      "time steps: 120000\n",
      "average reward: 818.6 average time: 187.2 best_reward: 1318.0\n",
      "time steps: 140000\n",
      "average reward: 776.7 average time: 169.8 best_reward: 1400.0\n",
      "time steps: 160000\n",
      "average reward: 869.7 average time: 168.6 best_reward: 1881.0\n",
      "time steps: 180000\n",
      "average reward: 840.3 average time: 183.4 best_reward: 1308.0\n",
      "time steps: 200000\n",
      "average reward: 761.4 average time: 151.3 best_reward: 1309.0\n",
      "Training ENV_NUM_4\n",
      "time steps: 40000\n",
      "average reward: 562.9 average time: 120.7 best_reward: 1028.0\n",
      "time steps: 80000\n",
      "average reward: 626.8 average time: 159.0 best_reward: 1285.0\n",
      "time steps: 120000\n",
      "average reward: 726.0 average time: 145.0 best_reward: 1137.0\n",
      "time steps: 160000\n",
      "average reward: 642.7 average time: 135.3 best_reward: 1122.0\n",
      "time steps: 200000\n",
      "average reward: 898.5 average time: 176.5 best_reward: 1307.0\n",
      "Training ENV_NUM_8\n",
      "time steps: 80000\n",
      "average reward: 667.0 average time: 140.2 best_reward: 1308.0\n",
      "time steps: 160000\n",
      "average reward: 728.3 average time: 148.5 best_reward: 1306.0\n",
      "Training ENV_NUM_16\n",
      "time steps: 160000\n",
      "average reward: 596.6 average time: 122.8 best_reward: 1108.0\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
